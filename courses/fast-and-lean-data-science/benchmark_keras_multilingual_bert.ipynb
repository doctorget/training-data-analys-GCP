{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f2ef93cd-2bc2-4681-bc6e-9a9395b25691",
    "_uuid": "ebd8119d-fb40-454f-a46f-940e80e7f8ce"
   },
   "source": [
    "# Overview\n",
    "\n",
    "It only takes one toxic comment to sour an online discussion. The Conversation AI team, a research initiative founded by [Jigsaw](https://jigsaw.google.com/) and Google, builds technology to protect voices in conversation. A main area of focus is machine learning models that can identify toxicity in online conversations, where toxicity is defined as anything *rude, disrespectful or otherwise likely to make someone leave a discussion*. Our API, [Perspective](http://perspectiveapi.com/), serves these models and others in a growing set of languages (see our [documentation](https://github.com/conversationai/perspectiveapi/blob/master/2-api/models.md#all-attribute-types) for the full list). If these toxic contributions can be identified, we could have a safer, more collaborative internet.\n",
    "\n",
    "In this competition, we'll explore how models for recognizing toxicity in online conversations might generalize across different languages. Specifically, in this notebook, we'll demonstrate this with a multilingual BERT (m-BERT) model. Multilingual BERT is pretrained on monolingual data in a variety of languages, and through this learns multilingual representations of text. These multilingual representations enable *zero-shot cross-lingual transfer*, that is, by fine-tuning on a task in one language, m-BERT can learn to perform that same task in another language (for some examples, see e.g. [How multilingual is Multilingual BERT?](https://arxiv.org/abs/1906.01502)).\n",
    "\n",
    "We'll study this zero-shot transfer in the context of toxicity in online conversations, similar to past competitions we've hosted ([[1]](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification), [[2]](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)). But rather than analyzing toxicity in English as in those competitions, here we'll ask you to do it in several different languages. For training, we're including the (English) datasets from our earlier competitions, as well as a small amount of new toxicity data in other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "593619be-8090-4dad-a462-e883e560ec1c",
    "_uuid": "cba509cb-708d-4fd0-8e2a-e5c1c7a0982d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "import os, time, logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from matplotlib import pyplot as plt\n",
    "print(tf.version.VERSION)\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae9fd8d4-bb00-4b3d-8452-0ec605f6ebba",
    "_uuid": "add2f478-e634-42db-b3c6-732ebd484ce3"
   },
   "source": [
    "# TPU or GPU detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "f5ccaf08-c532-4fde-9306-b897c890d0f8",
    "_uuid": "bc97f110-17eb-44dd-a792-d66c27a0b3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy() # works on GPU and multi-GPU\n",
    "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    tf.config.optimizer.set_jit(True) # XLA compilation\n",
    "    tf.keras.mixed_precision.experimental.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "# mixed precision\n",
    "# On TPU, bfloat16/float32 mixed precision is automatically used in TPU computations.\n",
    "# Enabling it in Keras also stores relevant variables in bfloat16 format (memory optimization).\n",
    "# This additional optimization was not used for TPUs in this sample.\n",
    "# On GPU, specifically V100, mixed precision must be enabled for hardware TensorCores to be used.\n",
    "# XLA compilation must be enabled for this to work. (On TPU, XLA compilation is the default and cannot be turned off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c55830a8-39e7-4607-9691-cd0848a092f7",
    "_uuid": "b1188d07-d23d-4d04-b9f5-125d16b982ed"
   },
   "source": [
    "# Configuration\n",
    "Set maximum sequence length and path variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "7acc953d-b1f6-4d29-a006-69af6839f7a9",
    "_uuid": "7d8d39c7-1fd2-4af7-a88a-9ca1242a6277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate schedule:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 128\n",
    "\n",
    "# Copy of the TF Hub model at https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1\n",
    "BERT_GCS_PATH = 'gs://bert_multilingual_public/bert_multi_cased_L-12_H-768_A-12_2/'\n",
    "EPOCHS = 6\n",
    "\n",
    "# select the GCS bucket closest to your accelerator\n",
    "GCS_PATH = 'gs://jigsaw_multilingual_toxic_comments_public/data'  # US\n",
    "#GCS_PATH = 'gs://jigsaw_multilingual_toxic_comments_public_euwest/data' # eu-west4\n",
    "\n",
    "if tpu:\n",
    "    BATCH_SIZE = 128 * strategy.num_replicas_in_sync\n",
    "else:\n",
    "    BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
    "\n",
    "TRAIN_DATA = GCS_PATH + \"/jigsaw-toxic-comment-train-processed-seqlen{}.csv\".format(SEQUENCE_LENGTH)\n",
    "TRAIN_DATA_LENGTH = 223549 # rows\n",
    "VALID_DATA = GCS_PATH + \"/validation-processed-seqlen{}.csv\".format(SEQUENCE_LENGTH)\n",
    "STEPS_PER_EPOCH = TRAIN_DATA_LENGTH // BATCH_SIZE\n",
    "\n",
    "LR_MAX = 0.001 * strategy.num_replicas_in_sync\n",
    "LR_EXP_DECAY = .9\n",
    "LR_MIN = 0.0001\n",
    "\n",
    "@tf.function\n",
    "def lr_fn(epoch):\n",
    "    lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch) + LR_MIN\n",
    "    return lr\n",
    "\n",
    "print(\"Learning rate schedule:\")\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "y = [lr_fn(x) for x in rng]\n",
    "plt.plot(rng, [lr_fn(x) for x in rng])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Define the model. We convert m-BERT's output to a final probabilty estimate. We're using an [m-BERT model from TensorFlow Hub](https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "fcd2093b-0774-4adf-9e4c-e9096f156d32",
    "_uuid": "1392a5e0-c8e4-46ea-b45d-0d9289682e09"
   },
   "outputs": [],
   "source": [
    "def multilingual_bert_model(max_seq_length=SEQUENCE_LENGTH):\n",
    "    \"\"\"Build and return a multilingual BERT model and tokenizer.\"\"\"\n",
    "    input_word_ids = tf.keras.layers.Input(\n",
    "        shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(\n",
    "        shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(\n",
    "        shape=(max_seq_length,), dtype=tf.int32, name=\"all_segment_id\")\n",
    "    \n",
    "    bert_layer = tf.saved_model.load(BERT_GCS_PATH)  # copy of TF Hub model 'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1'\n",
    "    bert_layer = hub.KerasLayer(bert_layer, trainable=True)\n",
    "\n",
    "    pooled_output, _ = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    output = tf.keras.layers.Dense(32, activation='relu')(pooled_output)\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='labels', dtype=tf.float32)(output)\n",
    "\n",
    "    return tf.keras.Model(inputs={'input_word_ids': input_word_ids,\n",
    "                                  'input_mask': input_mask,\n",
    "                                  'all_segment_id': segment_ids},\n",
    "                          outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "48479a32-25c1-40c9-bd1c-d076eb39d86e",
    "_uuid": "b24c47ad-a156-41f2-97b8-f5618181382c"
   },
   "source": [
    "# Dataset\n",
    "Load the preprocessed dataset. See the demo notebook for sample code for performing this preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string_list_into_ints(strlist):\n",
    "    s = tf.strings.strip(strlist)\n",
    "    s = tf.strings.substr(\n",
    "        strlist, 1, tf.strings.length(s) - 2)  # Remove parentheses around list\n",
    "    s = tf.strings.split(s, ',', maxsplit=SEQUENCE_LENGTH)\n",
    "    s = tf.strings.to_number(s, tf.int32)\n",
    "    s = tf.reshape(s, [SEQUENCE_LENGTH])  # Force shape here needed for XLA compilation (TPU)\n",
    "    return s\n",
    "\n",
    "def format_sentences(data, label='toxic', remove_language=False):\n",
    "    labels = {'labels': data.pop(label)}\n",
    "    if remove_language:\n",
    "        languages = {'language': data.pop('lang')}\n",
    "    # The remaining three items in the dict parsed from the CSV are lists of integers\n",
    "    for k,v in data.items():  # \"input_word_ids\", \"input_mask\", \"all_segment_id\"\n",
    "        data[k] = parse_string_list_into_ints(v)\n",
    "    return data, labels\n",
    "\n",
    "def make_sentence_dataset_from_csv(filename, label='toxic', language_to_filter=None):\n",
    "    # This assumes the column order label, input_word_ids, input_mask, segment_ids\n",
    "    SELECTED_COLUMNS = [label, \"input_word_ids\", \"input_mask\", \"all_segment_id\"]\n",
    "    label_default = tf.int32 if label == 'id' else tf.float32\n",
    "    COLUMN_DEFAULTS  = [label_default, tf.string, tf.string, tf.string]\n",
    "\n",
    "    if language_to_filter:\n",
    "        insert_pos = 0 if label != 'id' else 1\n",
    "        SELECTED_COLUMNS.insert(insert_pos, 'lang')\n",
    "        COLUMN_DEFAULTS.insert(insert_pos, tf.string)\n",
    "\n",
    "    preprocessed_sentences_dataset = tf.data.experimental.make_csv_dataset(\n",
    "        filename, column_defaults=COLUMN_DEFAULTS, select_columns=SELECTED_COLUMNS,\n",
    "        batch_size=1, num_epochs=1, shuffle=False)  # We'll do repeating and shuffling ourselves\n",
    "    # make_csv_dataset required a batch size, but we want to batch later\n",
    "    preprocessed_sentences_dataset = preprocessed_sentences_dataset.unbatch()\n",
    "    \n",
    "    if language_to_filter:\n",
    "        preprocessed_sentences_dataset = preprocessed_sentences_dataset.filter(\n",
    "            lambda data: tf.math.equal(data['lang'], tf.constant(language_to_filter)))\n",
    "        #preprocessed_sentences.pop('lang')\n",
    "    preprocessed_sentences_dataset = preprocessed_sentences_dataset.map(\n",
    "        lambda data: format_sentences(data, label=label,\n",
    "                                      remove_language=language_to_filter))\n",
    "\n",
    "    return preprocessed_sentences_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e006f30f-6350-45d5-b452-338c4bc78cc5",
    "_uuid": "10ff216a-2248-4104-858c-2b2461b42fba"
   },
   "source": [
    "Set up our data pipelines for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b17b24d7-1b0f-442b-bfd2-c42748bcd067",
    "_uuid": "864f31ac-8285-442b-93cf-dcae11d7fe62"
   },
   "outputs": [],
   "source": [
    "def make_dataset_pipeline(dataset, repeat_and_shuffle=True):\n",
    "    \"\"\"Set up the pipeline for the given dataset.\n",
    "    \n",
    "    Caches, repeats, shuffles, and sets the pipeline up to prefetch batches.\"\"\"\n",
    "    cached_dataset = dataset.cache()\n",
    "    if repeat_and_shuffle:\n",
    "        cached_dataset = cached_dataset.repeat().shuffle(2048)\n",
    "        cached_dataset = cached_dataset.batch(BATCH_SIZE, drop_remainder=True) # no remainder on repeated dataset\n",
    "    else:\n",
    "        cached_dataset = cached_dataset.batch(BATCH_SIZE)\n",
    "    cached_dataset = cached_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return cached_dataset\n",
    "\n",
    "# Load the preprocessed English dataframe.\n",
    "preprocessed_en_filename = TRAIN_DATA\n",
    "\n",
    "# Set up the dataset and pipeline.\n",
    "english_train_dataset = make_dataset_pipeline(\n",
    "    make_sentence_dataset_from_csv(preprocessed_en_filename))\n",
    "\n",
    "# Process the new datasets by language.\n",
    "preprocessed_val_filename = VALID_DATA\n",
    "\n",
    "nonenglish_val_datasets = {}\n",
    "for language_name, language_label in [('Spanish', 'es'), ('Italian', 'it'),\n",
    "                                      ('Turkish', 'tr')]:\n",
    "    nonenglish_val_datasets[language_name] = make_sentence_dataset_from_csv(\n",
    "        preprocessed_val_filename, language_to_filter=language_label)\n",
    "    nonenglish_val_datasets[language_name] = make_dataset_pipeline(\n",
    "        nonenglish_val_datasets[language_name], repeat_and_shuffle=False)\n",
    "\n",
    "nonenglish_val_datasets['Combined'] = make_sentence_dataset_from_csv(preprocessed_val_filename)\n",
    "nonenglish_val_datasets['Combined'] = make_dataset_pipeline(nonenglish_val_datasets['Combined'], repeat_and_shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ffd5c9ef-a806-4ae6-a1c5-8723ed822232",
    "_uuid": "0779be08-0502-47c0-b284-5f3d851de2e1"
   },
   "source": [
    "# Instantiate the model\n",
    "\n",
    "Compile our model. We will fine-tune the multilingual model on one of our English datasets, and then evaluate its performance on the new multilingual toxicity data. As our metric, we'll use the [AUC](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "422a984e-e571-4898-9667-b95d38416ddd",
    "_uuid": "e3d569ca-0bf4-4bde-aa69-95a46908f65a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "all_segment_id (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 177853441   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 all_segment_id[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           24608       keras_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "labels (Dense)                  (None, 1)            33          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 177,878,082\n",
      "Trainable params: 177,878,081\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    multilingual_bert = multilingual_bert_model()\n",
    "\n",
    "    # Compile the model. Optimize using stochastic gradient descent.\n",
    "    multilingual_bert.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001*strategy.num_replicas_in_sync),\n",
    "        metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "multilingual_bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "f477d7f4-20ec-4858-87d6-c041313ad276",
    "_uuid": "730e2b4b-6e7c-43f3-912e-3cbea3db62c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218/218 [==============================] - 61s 279ms/step - loss: 0.2377 - auc: 0.8477 - lr: 0.0080\n",
      "Epoch 2/6\n",
      "218/218 [==============================] - 61s 279ms/step - loss: 0.1466 - auc: 0.9510 - lr: 0.0072\n",
      "Epoch 3/6\n",
      "218/218 [==============================] - 61s 279ms/step - loss: 0.1278 - auc: 0.9637 - lr: 0.0065\n",
      "Epoch 4/6\n",
      "218/218 [==============================] - 61s 279ms/step - loss: 0.1195 - auc: 0.9684 - lr: 0.0059\n",
      "Epoch 5/6\n",
      "218/218 [==============================] - 61s 279ms/step - loss: 0.1152 - auc: 0.9708 - lr: 0.0053\n",
      "Epoch 6/6\n",
      "218/218 [==============================] - 61s 279ms/step - loss: 0.1120 - auc: 0.9722 - lr: 0.0048\n",
      "CPU times: user 24.1 s, sys: 1.48 s, total: 25.6 s\n",
      "Wall time: 6min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train on English Wikipedia comment data.\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_fn)\n",
    "history = multilingual_bert.fit(\n",
    "    english_train_dataset, steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS,\n",
    "    #validation_data=nonenglish_val_datasets['Combined'],\n",
    "    callbacks=[lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish loss, AUC after training: [0.5057603120803833, 0.8341767191886902]\n",
      "Italian loss, AUC after training: [0.5645029544830322, 0.7703384757041931]\n",
      "Turkish loss, AUC after training: [0.320696622133255, 0.9263491630554199]\n",
      "Combined loss, AUC after training: [0.4547185003757477, 0.8328021764755249]\n"
     ]
    }
   ],
   "source": [
    "# Performance on non-English comments after training.\n",
    "for language in nonenglish_val_datasets:\n",
    "    results = multilingual_bert.evaluate(nonenglish_val_datasets[language], verbose=0)\n",
    "    print('{} loss, AUC after training:'.format(language), results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This is not an official Google product but sample code provided for an educational purpose\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf22-cpu.2-2.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf22-cpu.2-2:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
